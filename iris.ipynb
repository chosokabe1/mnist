{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# データセットの読み込み\n",
    "# ====================\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "x, t = load_iris(return_X_y=True)\n",
    "\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1   x2   x3   x4    t\n",
       "0    5.1  3.5  1.4  0.2  0.0\n",
       "1    4.9  3.0  1.4  0.2  0.0\n",
       "2    4.7  3.2  1.3  0.2  0.0\n",
       "3    4.6  3.1  1.5  0.2  0.0\n",
       "4    5.0  3.6  1.4  0.2  0.0\n",
       "..   ...  ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3  2.0\n",
       "146  6.3  2.5  5.0  1.9  2.0\n",
       "147  6.5  3.0  5.2  2.0  2.0\n",
       "148  6.2  3.4  5.4  2.3  2.0\n",
       "149  5.9  3.0  5.1  1.8  2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# データの確認\n",
    "# ====================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(np.hstack((x, t.reshape(150, 1))), columns=[\"x1\", \"x2\", \"x3\", \"x4\", \"t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchで扱うために、データをTensor形式に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "変換前： <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "変換後： <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# データ形式の変換 (ndarray --> Tensor)\n",
    "# ====================\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"変換前：\", type(x), type(t))\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "t = torch.tensor(t, dtype=torch.int64)\n",
    "\n",
    "print(\"変換後：\", type(x), type(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchでは、訓練時に使用するデータ（xとt）を1つのオブジェクト（dataset）にまとめて格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初のサンプル： (tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor(0))\n",
      "最初のサンプルの特徴ベクトル： tensor([5.1000, 3.5000, 1.4000, 0.2000])\n",
      "最初のサンプルの目標値： tensor(0)\n",
      "最後のサンプル： (tensor([5.9000, 3.0000, 5.1000, 1.8000]), tensor(2))\n",
      "最後のサンプルの特徴ベクトル： tensor([5.9000, 3.0000, 5.1000, 1.8000])\n",
      "最後のサンプルの目標値： tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# データをまとめてデータセットのオブジェクトを構築\n",
    "# ====================\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(x, t)\n",
    "\n",
    "print(\"最初のサンプル：\", dataset[0])\n",
    "print(\"最初のサンプルの特徴ベクトル：\", dataset[0][0])\n",
    "print(\"最初のサンプルの目標値：\", dataset[0][1])\n",
    "\n",
    "print(\"最後のサンプル：\", dataset[-1])\n",
    "print(\"最後のサンプルの特徴ベクトル：\", dataset[-1][0])\n",
    "print(\"最後のサンプルの目標値：\", dataset[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを、訓練用（training）・検証用（validation）・評価用（test）に分割する。\n",
    "\n",
    "深層学習では、充分多くのデータを扱えることが前提のため、交差検証をする代わりにハイパラ調整のための検証用データを切り分ける。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# 訓練用・検証用・評価用に6:2:2で分割\n",
    "# ====================\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "n_train = int(len(dataset) * 0.6)\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "# ランダムに分割するので、再現性の確保のためにランダムシードを固定\n",
    "torch.manual_seed(42)\n",
    "train, val, test = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader を用いてデータセットからバッチサイズ分のサンプルを取得し、ミニバッチ学習を行う。\n",
    "\n",
    "ミニバッチ学習では、訓練データのみシャッフルしながらサンプルを抽出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 訓練用・検証用・評価用の各データをDataLoaderに格納\n",
    "# ====================\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size)\n",
    "test_loader = DataLoader(test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ネットワークの定義\n",
    "\n",
    "今回は、特徴量が4種類、クラス数が3種類なので、4次元1層の中間層を持つMLPを用いることにする。\n",
    "\n",
    "PyTorchでは、ネットワークの記述にクラスを使う。\n",
    "\n",
    "全結合層などパラメタを含んだ層を `__init__()` メソッド内に定義し、順伝播の計算を `forward()` メソッド内に記述する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# MLPを定義\n",
    "# ====================\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # 使用するオブジェクトを定義\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)  # 4層の入力層から4層の中間層への全結合\n",
    "        self.fc2 = nn.Linear(4, 3)  # 4層の中間層から3層の出力層への全結合\n",
    "    \n",
    "    # 順伝播\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))  # xを線形変換（fc1）し、非線形変換（relu）し、中間表現hを得る\n",
    "        y = self.fc2(h)  # 中間表現hを線形変換（fc2）し、出力yを得る\n",
    "        return y\n",
    "\n",
    "# ネットワークのインスタンスを作成\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 損失関数の選択\n",
    "\n",
    "今回は分類問題を扱うので、損失関数としてクロスエントロピーを採用する。\n",
    "\n",
    "PyTorchでは、損失関数を `criterion` という名前で定義するのが慣習である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 最適化手法の選択\n",
    "\n",
    "パラメタ更新に用いる最適化手法を選ぶ。\n",
    "\n",
    "PyTorchでは、最適化手法を `optimizer` という名前で定義するのが慣習である。\n",
    "\n",
    "今回は、基本的な最適化手法である確率的勾配降下法（SGD）を採用する。\n",
    "\n",
    "Optimizerの引数には、ネットワークのパラメタと学習率を設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ネットワークの学習\n",
    "\n",
    "深層学習では、GPUによる高速演算を利用するのが一般的である。\n",
    "\n",
    "GPUを使う際には、訓練時にモデルとデータの両方をGPUのメモリ上に転送する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# モデルをGPUへ転送\n",
    "# ====================\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 正解率の計算（検証セット評価セット用）\n",
    "# ====================\n",
    "\n",
    "def calc_acc(data_loader):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        accs = list()\n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "\n",
    "            label = torch.argmax(y, dim=1)\n",
    "            acc = (label == t).sum() * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "\n",
    "    return torch.tensor(accs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 訓練ループ\n",
    "# ====================\n",
    "\n",
    "max_epoch = 30\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    # ミニバッチ学習\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # バッチサイズ分のサンプルを抽出\n",
    "        x, t = batch  # 1\n",
    "\n",
    "        # データをGPUへ転送\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        # 勾配を初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播\n",
    "        y = net(x)  # 2\n",
    "        loss = criterion(y, t)  # 3\n",
    "\n",
    "        # 学習状況の確認\n",
    "        label = torch.argmax(y, dim=1)\n",
    "        acc = (label == t).sum() * 1.0 / len(t)\n",
    "        print(\"epoch: %d    loss: %.3f    acc: %.3f\" % (epoch+1, loss.item(), acc))\n",
    "\n",
    "        # 誤差逆伝播\n",
    "        loss.backward()  # 4\n",
    "        optimizer.step()  # 5\n",
    "    \n",
    "    # 検証データの性能を確認\n",
    "    val_acc = calc_acc(val_loader)\n",
    "    print(\"epoch: %d    val_acc: %.3f\" % (epoch+1, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================\n",
    "# 評価用データで性能確認\n",
    "# ====================\n",
    "\n",
    "test_acc = calc_acc(test_loader)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# confusion_matrix\n",
    "#\n",
    "\n",
    "nb_classes = 3\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        y = net(x)\n",
    "\n",
    "        label = torch.argmax(y, dim=1)\n",
    "        for t_conf, p in zip(t.view(-1), label.view(-1)):\n",
    "            confusion_matrix[t_conf.long(), p.long()] += 1\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "confusion_matrix_numpy = confusion_matrix.to('cpu').detach().numpy().copy()\n",
    "df_cmx = pd.DataFrame(confusion_matrix_numpy)\n",
    "plt.figure(figsize= (12,7))\n",
    "sn.heatmap(df_cmx, annot=True, fmt='g', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.cuda116': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14d1fb042f216637d05a2d1db7ab9431559fb26a743a78158ba3a741f4f51867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
